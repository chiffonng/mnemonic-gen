\section{Discussion} \label{sec:discussion}

Our research demonstrates that reasoning LLMs can generate linguistically grounded mnemonics according to our proposed taxonomy of linguistic features (\Cref{tab:linguistic-features}) and VAM model of effective mnemonics (\Cref{app:mnemonic-characteristics}). By leveraging the inherent linguistic knowledge of these models, we can create mnemonics that learners prefer and enhance learners' understanding beyond the scope of the vocabulary word itself. This approach has significant implications for educational applications, particularly in vocabulary acquisition.

The in-context learning experiments revealed that requesting explicit linguistic feature analysis prior to mnemonic creation produces higher-quality memory aids that leverage meaningful word associations. This structured linguistic analysis approach encouraged models to explore linguistic features (e.g., etymological roots, morphological components, semantic relationships) that create robust memory hooks for learners. Simply instructing the model to generate "linguistically grounded mnemonics" aligning with the VAM model (\Cref{app:mnemonic-characteristics}) and providing a structured output format substantially improved the quality and consistency of generated mnemonics. Adding examples of linguistic reasoning before mnemonic generation in the prompt further enhanced performance, guiding models to balance linguistic grounding and memorability. This finding aligns with previous research indicating that structured prompts and examples can significantly improve LLM performance on complex tasks \citep{brownFewShotLearners2020,yinDidYouRead2023}.

We successfully distilled the linguistic reasoning capabilities from the teacher model \teachermodel to our student model \studentmodel to create \linksys, a smaller and more accessible model capable of generating high-quality mnemonics, using GRPO \citep{DeepSeek-AIDEEPSEEKR12025}. The resulting \linksys model demonstrated strong performance in generating \lgms, outperforming the base model in both LLM-as-a-judge evaluations and pairwise preference annotations (blind study). \linksys scores higher on all five metrics (correct usage of vocabulary, linguistic grounding, memorability, clarity, and overall quality) compared to the base model, with statistically significant differences in the last four metrics and small-to-medium effect sizes for the last three metrics. Our annotators, as English learners, consistently prefer mnemonics generated by \linksys. With its size and performance, \linksys is a promising candidate for deployment in educational contexts, particularly in low-resource environments, to interact with students in a helpful and personalized way for vocabulary learning as a linguist and vocabulary buddy.

\section{Conclusion} \label{sec:conclusion}
This paper introduced a novel approach to English vocabulary learning through linguistically grounded mnemonics generated by language models. We proposed a taxonomy of linguistic features and characteristics that contribute to effective mnemonics, developed techniques for prompting LLMs to generate high-quality mnemonics, and created a specialized model (\linksys) capable of generating linguistically grounded mnemonics that outperform those from base models. Our evaluation demonstrates that mnemonics that incorporate etymological, morphological, phonetic, orthographic, and semantic features are not only more preferred by learners but also potentially more effective for vocabulary retention.

\subsection{Limitations} \label{sec:limitations}
Despite promising results, several limitations warrant acknowledgment. (1) Resource constraints limited the scale of our experiments (\Cref{sec:icl-performance,sec:evaluation}) and the limited number of annotators in our double-blind study (\Cref{sec:pairwise-preference}) may have introduced bias in the evaluation process. Future work should consider using a larger and more diverse set of judges and annotators to ensure robustness and generalizability of the findings.

(2) Our evaluation focused primarily on intermediate measures of mnemonic quality rather than direct assessment of learning outcomes. Future work should include longitudinal studies measuring actual vocabulary retention using LLM-generated mnemonics.

(3) The use of LLM-as-a-judge for qualitative grading and pairwise preference evaluation may introduce biases. We acknowledged the potential for biases in LLMs, including self-enhancement bias \citep{panicksseryLLMEvaluatorsRecognize2024}, positional bias \citep{wangNotFairEvaluators2024,zhengJudgingLLMasajudgeMTbench2023}, verbosity bias \citep{zhengJudgingLLMasajudgeMTbench2023}, and others. Respectively, we attempted to mitigate these biases by employing a structured evaluation protocol, shuffling the order of mnemonics in a pair, enforcing a structured output format, and controlling for generated mnemonics length by both models in comparison \citep{guSurveyLLMasaJudge2025}. Additionally, we employed a double-blind annotation study with human annotators to validate the results. However, the limited number of annotators (two) may have introduced bias in the evaluation process. Future work should consider using a larger and more diverse set of judges and annotators to ensure robustness and generalizability of the findings.

(4) The focus on English words and English mnemonics may limit the generalizability of our findings to other types of vocabulary (e.g., phrasal verbs, idioms), other languages, and cross-lingual vocabulary-mnemonics. Future research should explore the applicability of our approach to different languages and cultural contexts, such as generating Vietnamese mnemonics to help learn Chinese vocabulary through radicals and cognates.

\subsection{Future Work} \label{sec:future-work}

The development of \linksys represents a step toward more accessible and personalized educational AI tools that don't require extensive computational resources. By distilling linguistic reasoning capabilities from larger models into smaller, more deployable ones, we have created a practical solution for vocabulary learning applications. Future work should focus on expanding the linguistic scope to include additional languages and vocabulary types, developing more sophisticated evaluation methods that directly measure learning outcomes, and exploring multimodal approaches that combine textual mnemonics with visual elements to further enhance memorability and learning effectiveness.
